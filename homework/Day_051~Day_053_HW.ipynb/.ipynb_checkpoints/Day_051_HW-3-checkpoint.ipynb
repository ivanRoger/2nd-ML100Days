{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "DATA_path = r\"C:\\Users\\user\\Documents\\GitHub\\2nd-ML100Days\\homework\\Day_051_HW.ipynb\\ml100marathon-02-01\"\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff_file = 'dfoff.pkl'\n",
    "dftest_file = 'dftest.pkl'\n",
    "def loadData():\n",
    "    if os.path.isfile(dfoff_file) and os.path.isfile(dfoff_file):\n",
    "        dfoff = pd.read_pickle(dfoff_file)\n",
    "        dftest = pd.read_pickle(dftest_file)\n",
    "    else:\n",
    "        dfoff = pd.read_csv(os.path.join(DATA_path,'train_offline.csv'))\n",
    "        dftest = pd.read_csv(os.path.join(DATA_path,'test_offline.csv'))\n",
    "        dftest = dftest[~dftest.Date_received.isna()]\n",
    "        dftest.reset_index(drop=True, inplace=True)\n",
    "        print(dfoff.shape)\n",
    "        print(dftest.shape)\n",
    "        dfoff = dfoff.drop_duplicates()\n",
    "        dfoff.head(3)\n",
    "\n",
    "        ## Creat target label \n",
    "        \"\"\"\n",
    "        According to the definition, \n",
    "        1) buy with coupon within (include) 15 days ==> 1\n",
    "        2) buy with coupon but out of 15 days ==> 0\n",
    "        3) buy without coupon ==> -1 (we don't care)\n",
    "        \"\"\"\n",
    "        def label(row):\n",
    "            if np.isnan(row['Date_received']):\n",
    "                return -1\n",
    "            if not np.isnan(row['Date']):\n",
    "                td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "                if td <= pd.Timedelta(15, 'D'):\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "        dfoff[\"label\"].value_counts()\n",
    "        # Generate features - weekday acquired coupon\n",
    "        def getWeekday(row):\n",
    "            if (np.isnan(row)) or (row==-1):\n",
    "                return row\n",
    "            else:\n",
    "                return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n",
    "\n",
    "        dfoff['weekday'] = dfoff['Date_received'].apply(getWeekday)\n",
    "        dftest['weekday'] = dftest['Date_received'].apply(getWeekday)\n",
    "        # Generate features - coupon discount and distance\n",
    "        def getDiscountType(row):\n",
    "            if row == 'null':\n",
    "                return 'null'\n",
    "            elif ':' in row:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def convertRate(row):\n",
    "            \"\"\"Convert discount to rate\"\"\"\n",
    "            if row == 'null':\n",
    "                return 1.0\n",
    "            elif ':' in row:\n",
    "                rows = row.split(':')\n",
    "                return 1.0 - float(rows[1])/float(rows[0])\n",
    "            else:\n",
    "                return float(row)\n",
    "\n",
    "        def getDiscountMan(row):\n",
    "            if ':' in row:\n",
    "                rows = row.split(':')\n",
    "                return int(rows[0])\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def getDiscountJian(row):\n",
    "            if ':' in row:\n",
    "                rows = row.split(':')\n",
    "                return int(rows[1])\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def processData(df):\n",
    "\n",
    "            # convert discunt_rate\n",
    "            df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "            df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "            df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "            df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "\n",
    "            return df\n",
    "\n",
    "        dfoff = processData(dfoff)\n",
    "        dftest = processData(dftest)\n",
    "\n",
    "        def split_train_valid(row, date_cut=\"20160416\"):\n",
    "            if (np.isnan(row)) or (row==-1):\n",
    "                return False\n",
    "            else:\n",
    "                is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "            return is_train\n",
    "\n",
    "        dfoff[\"is_train\"] = dfoff[\"Date_received\"].apply(split_train_valid)\n",
    "        \n",
    "        dfoff.to_pickle(dfoff_file)\n",
    "        dftest.to_pickle(dftest_file)\n",
    "    return dfoff,dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 9)\n",
      "(1124653, 14)\n",
      "(306313, 14)\n"
     ]
    }
   ],
   "source": [
    "dfoff, dftest = loadData()\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "statistic_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff.loc[dfoff.Distance.isna(), \"Distance\"] = 11 # df.Distance.max()\n",
    "dftest.loc[dftest.Distance.isna(), \"Distance\"] = 11 # df.Distance.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569988867596217\n"
     ]
    }
   ],
   "source": [
    "# u_count Purchase Count Group by  User_id \n",
    "df = dfoff[dfoff[\"label\"]!=0]\n",
    "count_df = df.groupby(['User_id']).size().reset_index(name='u_count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['User_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['User_id'], how='left')\n",
    "print((dftest['u_count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('u_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190240048577762\n"
     ]
    }
   ],
   "source": [
    "# u_1count Coupon Purchase Count Group by  User_id \n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['User_id']).size().reset_index(name='u_1count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['User_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['User_id'], how='left')\n",
    "print((dftest['u_1count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('u_1count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7421950749723322\n"
     ]
    }
   ],
   "source": [
    "# um_count Purchase Count Group by User_id, Merchant_id \n",
    "df = dfoff[dfoff[\"label\"]!=0]\n",
    "count_df = df.groupby(['User_id','Merchant_id']).size().reset_index(name='um_count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['User_id','Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['User_id','Merchant_id'], how='left')\n",
    "print((dftest['um_count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('um_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641543127454597\n"
     ]
    }
   ],
   "source": [
    "# um_count Coupon Purchase Count Group by User_id, Merchant_id \n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['User_id','Merchant_id']).size().reset_index(name='um_1count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['User_id','Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['User_id','Merchant_id'], how='left')\n",
    "print((dftest['um_1count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('um_1count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023596778458635448\n"
     ]
    }
   ],
   "source": [
    "# m_count Purchase Count Group by Merchant_id\n",
    "df = dfoff[dfoff[\"label\"]!=0]\n",
    "count_df = df.groupby(['Merchant_id']).size().reset_index(name='m_count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18789930561223323\n"
     ]
    }
   ],
   "source": [
    "# m_1count Purchase Count Group by Merchant_id\n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['Merchant_id']).size().reset_index(name='m_1count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_1count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_1count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8637374189146396\n"
     ]
    }
   ],
   "source": [
    "# c_1count Purchase Count Group by Coupon_id\n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['Coupon_id']).size().reset_index(name='c_1count')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Coupon_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Coupon_id'], how='left')\n",
    "print((dftest['c_1count'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('c_1count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023596778458635448\n"
     ]
    }
   ],
   "source": [
    "# m_distance_mean Purchase Count Group by User_id\n",
    "df = dfoff[dfoff[\"label\"]!=0]\n",
    "count_df = df.groupby(['Merchant_id'])['Distance'].mean().reset_index(name='m_distance_mean')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_distance_mean'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_distance_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023596778458635448\n"
     ]
    }
   ],
   "source": [
    "# m_distance_max Purchase Count Group by User_id\n",
    "df = dfoff[dfoff[\"label\"]!=0]\n",
    "count_df = df.groupby(['Merchant_id'])['Distance'].mean().reset_index(name='m_distance_max')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_distance_max'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_distance_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18789930561223323\n"
     ]
    }
   ],
   "source": [
    "# m_1distance_mean Purchase Count Group by User_id\n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['Merchant_id'])['Distance'].mean().reset_index(name='m_1distance_mean')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_1distance_mean'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_1distance_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18789930561223323\n"
     ]
    }
   ],
   "source": [
    "# m_1distance_max Purchase Count Group by User_id\n",
    "df = dfoff[dfoff[\"label\"]==1]\n",
    "count_df = df.groupby(['Merchant_id'])['Distance'].mean().reset_index(name='m_1distance_max')\n",
    "dfoff = pd.merge(dfoff, count_df, on=['Merchant_id'], how='left')\n",
    "dftest = pd.merge(dftest, count_df, on=['Merchant_id'], how='left')\n",
    "print((dftest['m_1distance_max'].isnull().sum()/dftest.shape[0]))\n",
    "statistic_cols.append('m_1distance_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday_type (weekend = 1)\n",
    "dfoff['weekday_type'] = dfoff['weekday'].apply(lambda x : 1 if x in [6,7] else 0 ) # apply to trainset\n",
    "dftest['weekday_type'] = dftest['weekday'].apply(lambda x : 1 if x in [6,7] else 0 ) # apply to testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>weekday</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>m_1distance_mean</th>\n",
       "      <th>m_1distance_max</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "\n",
       "         Date  label  weekday  discount_rate  ...  m_1distance_mean  \\\n",
       "0  20160217.0     -1      NaN            NaN  ...               1.0   \n",
       "1         NaN      0      3.0           0.95  ...               1.0   \n",
       "2         NaN      0      6.0           0.95  ...               1.0   \n",
       "\n",
       "   m_1distance_max  weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
       "0              1.0             0          0          0          0          0   \n",
       "1              1.0             0          0          0          1          0   \n",
       "2              1.0             1          0          0          0          0   \n",
       "\n",
       "   weekday_5  weekday_6  weekday_7  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          1          0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "dfoff.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>to_testset</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>m_1distance_mean</th>\n",
       "      <th>m_1distance_max</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160516.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160516.0   \n",
       "\n",
       "         Date  label  to_testset  weekday  ...  m_1distance_mean  \\\n",
       "0         NaN      0        True        6  ...          2.285714   \n",
       "1         NaN      0        True        1  ...          1.000000   \n",
       "2  20160613.0      0        True        1  ...          1.000000   \n",
       "\n",
       "   m_1distance_max  weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
       "0         2.285714             1          0          0          0          0   \n",
       "1         1.000000             0          1          0          0          0   \n",
       "2         1.000000             0          1          0          0          0   \n",
       "\n",
       "   weekday_5  weekday_6  weekday_7  \n",
       "0          0          1          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf = pd.get_dummies(dftest['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf\n",
    "dftest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_count 0.40736031469262074 0.5569988867596217\n",
      "u_1count 0.847072830464152 0.9190240048577762\n",
      "um_count 0.48879521061162867 0.7421950749723322\n",
      "um_1count 0.892905634004444 0.9641543127454597\n",
      "m_count 0.00046058650979457664 0.023596778458635448\n",
      "m_1count 0.06662232706443677 0.18789930561223323\n",
      "c_1count 0.38453549672654586 0.8637374189146396\n",
      "m_distance_mean 0.00046058650979457664 0.023596778458635448\n",
      "m_distance_max 0.00046058650979457664 0.023596778458635448\n",
      "m_1distance_mean 0.06662232706443677 0.18789930561223323\n",
      "m_1distance_max 0.06662232706443677 0.18789930561223323\n"
     ]
    }
   ],
   "source": [
    "good_statistic_cols = []\n",
    "for c in statistic_cols:\n",
    "    ratio = dftest[c].isnull().sum()/dftest.shape[0]\n",
    "    print(c,(dfoff[c].isnull().sum()/dfoff.shape[0]),ratio)\n",
    "    if (ratio<0.75):\n",
    "        good_statistic_cols.append(c)\n",
    "    dfoff[c] = dfoff[c].fillna(0)\n",
    "    dftest[c] = dftest[c].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 632003, #positive: 30506\n",
      "Valid size: 78877, #positive: 3769\n",
      "21 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7', 'u_count', 'um_count', 'm_count', 'm_1count', 'm_distance_mean', 'm_distance_max', 'm_1distance_mean', 'm_1distance_max']\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "df = dfoff[dfoff['label'] != -1].copy()\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))\n",
    "\n",
    "original_feature = ['discount_rate',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance', \n",
    "                    'weekday_type'] + weekdaycols + good_statistic_cols\n",
    "print(len(original_feature),original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>Distance</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>u_count</th>\n",
       "      <th>um_count</th>\n",
       "      <th>m_count</th>\n",
       "      <th>m_1count</th>\n",
       "      <th>m_distance_mean</th>\n",
       "      <th>m_distance_max</th>\n",
       "      <th>m_1distance_mean</th>\n",
       "      <th>m_1distance_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15813.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1.251945</td>\n",
       "      <td>1.251945</td>\n",
       "      <td>2.042208</td>\n",
       "      <td>2.042208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  discount_type  discount_man  discount_jian  Distance  \\\n",
       "0           0.95              1            20              1       0.0   \n",
       "1           0.95              1            20              1       0.0   \n",
       "2           0.90              1           200             20       1.0   \n",
       "\n",
       "   weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  ...  weekday_6  \\\n",
       "0             0          0          0          1          0  ...          0   \n",
       "1             1          0          0          0          0  ...          1   \n",
       "2             0          0          0          0          0  ...          0   \n",
       "\n",
       "   weekday_7  u_count  um_count  m_count  m_1count  m_distance_mean  \\\n",
       "0          0      1.0       1.0     14.0       1.0         1.357143   \n",
       "1          0      1.0       1.0     14.0       1.0         1.357143   \n",
       "2          0      0.0       0.0  15813.0    1540.0         1.251945   \n",
       "\n",
       "   m_distance_max  m_1distance_mean  m_1distance_max  \n",
       "0        1.357143          1.000000         1.000000  \n",
       "1        1.357143          1.000000         1.000000  \n",
       "2        1.251945          2.042208         2.042208  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = original_feature\n",
    "train[predictors].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           595694\n",
       "weekday_7           0\n",
       "u_1count            0\n",
       "Merchant_id         0\n",
       "Coupon_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(632003, 33)\n",
      "(632003, 21)\n",
      "(78877, 21)\n",
      "(632003,)\n",
      "(78877,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>Distance</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>u_count</th>\n",
       "      <th>um_count</th>\n",
       "      <th>m_count</th>\n",
       "      <th>m_1count</th>\n",
       "      <th>m_distance_mean</th>\n",
       "      <th>m_distance_max</th>\n",
       "      <th>m_1distance_mean</th>\n",
       "      <th>m_1distance_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15813.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1.251945</td>\n",
       "      <td>1.251945</td>\n",
       "      <td>2.042208</td>\n",
       "      <td>2.042208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  discount_type  discount_man  discount_jian  Distance  \\\n",
       "0           0.95              1            20              1       0.0   \n",
       "1           0.95              1            20              1       0.0   \n",
       "2           0.90              1           200             20       1.0   \n",
       "\n",
       "   weekday_type  weekday_1  weekday_2  weekday_3  weekday_4  ...  weekday_6  \\\n",
       "0             0          0          0          1          0  ...          0   \n",
       "1             1          0          0          0          0  ...          1   \n",
       "2             0          0          0          0          0  ...          0   \n",
       "\n",
       "   weekday_7  u_count  um_count  m_count  m_1count  m_distance_mean  \\\n",
       "0          0      1.0       1.0     14.0       1.0         1.357143   \n",
       "1          0      1.0       1.0     14.0       1.0         1.357143   \n",
       "2          0      0.0       0.0  15813.0    1540.0         1.251945   \n",
       "\n",
       "   m_distance_max  m_1distance_mean  m_1distance_max  \n",
       "0        1.357143          1.000000         1.000000  \n",
       "1        1.357143          1.000000         1.000000  \n",
       "2        1.251945          2.042208         2.042208  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train[predictors].shape)\n",
    "print(valid[predictors].shape)\n",
    "print(train['label'].shape)\n",
    "print(valid['label'].shape)\n",
    "train[predictors].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                704       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# simple early stopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(21,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation=\"relu\")) \n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(632003, 21)\n",
      "Train on 632003 samples, validate on 78877 samples\n",
      "Epoch 1/50\n",
      "  5376/632003 [..............................] - ETA: 2:57 - loss: 2.8174 - acc: 0.6592"
     ]
    }
   ],
   "source": [
    "print(train[predictors].shape)\n",
    "model_history = model.fit(x=train[predictors], y=train['label'],\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs, shuffle=True,\n",
    "                          validation_data=(valid[predictors], valid['label']),\n",
    "                          callbacks=[earlystop,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "\n",
    "train_loss = model_history.history['loss']\n",
    "train_acc = model_history.history['acc']\n",
    "valid_loss = model_history.history['val_loss']\n",
    "valid_acc = model_history.history['val_acc']\n",
    "plt.plot(train_loss, 'b', label='train')\n",
    "plt.plot(valid_loss, 'r', label='valid')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc, 'b', label='train')\n",
    "plt.plot(valid_acc, 'r', label='valid')\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = saved_model.predict(valid[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred)\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset.copy()\n",
    "\n",
    "y_test_pred = saved_model.predict(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], pd.DataFrame(y_test_pred[:])), axis=1)\n",
    "output.columns = [\"User_id\", \"Coupon_id\", \"Date_received\",\"pred_prob\"]\n",
    "print(output.shape)\n",
    "output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"midterm_exam2.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
